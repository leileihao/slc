{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leileihao/slc/blob/main/model_stage2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQk3Vf7PBceD"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hX7mTwPDG2Ki",
        "outputId": "1b314748-9c9a-4d3d-84a1-b9c4dc2d580c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GQtRZtECAH8g"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import scipy.io as so\n",
        "from scipy import stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import f1_score, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.transforms import Normalize\n",
        "from torch.autograd import Variable\n",
        "from pandas import Series\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/WeberLab/')\n",
        "import sleepy\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNDGQU7AbCOX"
      },
      "source": [
        "### Sleepy Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yy6mZ0O0bIhW"
      },
      "outputs": [],
      "source": [
        "# Modified specifically to look at the 3_remix sleep state file\n",
        "def load_stateidx(ppath, name, ann_name=''):\n",
        "    \"\"\" load the sleep state file of recording (folder) $ppath/$name\n",
        "    @Return:\n",
        "        M,K         sequence of sleep states, sequence of\n",
        "                    0'1 and 1's indicating non- and annotated states\n",
        "    \"\"\"\n",
        "    ddir = os.path.join(ppath, name)\n",
        "    ppath, name = os.path.split(ddir)\n",
        "\n",
        "    if ann_name == '':\n",
        "        ann_name = name\n",
        "\n",
        "    remidxfile3 = os.path.join(ppath, name, '3_remidx_' + ann_name + '.txt')\n",
        "    remidxfile_regular = os.path.join(ppath, name, 'remidx_' + ann_name + '.txt')\n",
        "\n",
        "    # Check if '3_remidx_' file exists, if not use 'remidx_' file\n",
        "    if os.path.exists(remidxfile3):\n",
        "      remidxfile = remidxfile3\n",
        "    else:\n",
        "      remidxfile = remidxfile_regular\n",
        "\n",
        "\n",
        "    f = open(remidxfile, 'r')\n",
        "    lines = f.readlines()\n",
        "    f.close()\n",
        "\n",
        "    n = 0\n",
        "    for l in lines:\n",
        "        if re.match('\\d', l):\n",
        "            n += 1\n",
        "\n",
        "    M = np.zeros(n, dtype='int')\n",
        "    K = np.zeros(n, dtype='int')\n",
        "\n",
        "    i = 0\n",
        "    for l in lines :\n",
        "\n",
        "        if re.search('^\\s+$', l) :\n",
        "            continue\n",
        "        if re.search('\\s*#', l) :\n",
        "            continue\n",
        "\n",
        "        if re.match('\\d+\\s+-?\\d+', l) :\n",
        "            a = re.split('\\s+', l)\n",
        "            M[i] = int(a[0])\n",
        "            K[i] = int(a[1])\n",
        "            i += 1\n",
        "\n",
        "    return M,K\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O4zpJg97G2QI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, data, labels, window_size):\n",
        "    self.data = torch.tensor(data, dtype=torch.float32)\n",
        "    self.labels = torch.tensor(labels, dtype=torch.uint8)\n",
        "    self.window_size = window_size\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data) // self.window_size\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = self.data[index*window_size:index*window_size+window_size][:]\n",
        "    print()\n",
        "    if (index*window_size >= (len(self.data) - window_size)):\n",
        "      y = self.labels[index*window_size-1]\n",
        "    else:\n",
        "      y = self.labels[index*window_size] # so it doesn't have an out of bound\n",
        "\n",
        "    y = y.long()\n",
        "\n",
        "    # Perform one-hot encoding on y\n",
        "    y = y - 1 # shift the labels to start at 0\n",
        "    y_encoded = F.one_hot(y, num_classes = 3)\n",
        "\n",
        "    x = x.view(-1, 2)\n",
        "\n",
        "    return x, y_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 1 Preparations for Stage 2"
      ],
      "metadata": {
        "id": "lmLsQto_9-kD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUA36yP_tFdb"
      },
      "source": [
        "## Stage 1 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUx61TQnzB9h",
        "outputId": "3d488ffd-0a3a-47e6-d51a-60f62218c52f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check that GPU is being used for model\n",
        "torch.manual_seed(46) # For consistency\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FH_nSi9irJu8"
      },
      "outputs": [],
      "source": [
        "from torch import sparse\n",
        "# Bidirectional LSTM\n",
        "class biLSTM(nn.Module):\n",
        "  def __init__(self, input_size, window_len, hidden_size=128, num_layers=2, dropout=0.2):\n",
        "    super(biLSTM, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers,\n",
        "                            dropout=dropout, batch_first=True, bidirectional=True)\n",
        "    self.fc = nn.Sequential(\n",
        "          nn.BatchNorm1d(hidden_size*2),\n",
        "          nn.Linear(hidden_size*2, hidden_size),\n",
        "          nn.ReLU(),\n",
        "          nn.BatchNorm1d(hidden_size),\n",
        "          nn.Linear(hidden_size, 64),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(64, 3), # three brain states: 1, 2, 3 (--> now 0, 1, 2 due to shift)\n",
        "    )\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, seq_len, num_channels = x.size()\n",
        "\n",
        "    h0 = torch.randn(2 * self.num_layers, batch_size, self.hidden_size).double().to(device)\n",
        "    c0 = torch.randn(2 * self.num_layers, batch_size, self.hidden_size).double().to(device)\n",
        "\n",
        "    x = x.permute(0, 1, 2)  # Transpose the tensor to match the shape (batch, seq_len, num_channels)\n",
        "\n",
        "    outl, _ = self.lstm(x, (h0, c0))\n",
        "    out = outl[:, -1, :]\n",
        "\n",
        "    out = self.fc(out)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmuVpCeybBbX"
      },
      "source": [
        "## Process the unshuffled EEG through the Stage 1 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AivdaKU4PGwl"
      },
      "outputs": [],
      "source": [
        "random.seed(46)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idOg-yHCMoLY"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import pickle\n",
        "class CPU_Unpickler(pickle.Unpickler):\n",
        "    def find_class(self, module, name):\n",
        "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
        "            return lambda b: torch.load(io.BytesIO(b), map_location=device)\n",
        "        else: return super().find_class(module, name)\n",
        "\n",
        "biLSTM_model = CPU_Unpickler(open('drive/My Drive/MultiVanillaModelPart1N.pkl',\"rb\")).load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFHyqo6vGJY8"
      },
      "outputs": [],
      "source": [
        "# Create segments for training\n",
        "def create_segments(array, segment_length, overlap):\n",
        "    segments = []\n",
        "    stride = segment_length - overlap\n",
        "    for i in range(0, len(array) - segment_length + 1, stride):\n",
        "        segments.append(array[i:i+segment_length])\n",
        "    return segments\n",
        "\n",
        "segment_length = 51\n",
        "overlap = 50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MYakOCLUgQU",
        "outputId": "84bab973-4622-4071-bcc8-89858cbfba0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['c18_020418n1',\n",
              " 'c19_020418n1',\n",
              " 'c20_020618n1',\n",
              " 'c21_020618n1',\n",
              " 'c30_030418n1',\n",
              " 'J10_052318n1',\n",
              " 'J45_100918n1',\n",
              " 'J12_052818n1',\n",
              " 'J35_082118n1',\n",
              " 'J46_100918n1',\n",
              " 'J9_052318n1',\n",
              " 'c36_032518n1',\n",
              " 'J17_062618n1',\n",
              " 'AC81_081221n1',\n",
              " 'AC85_082321n1']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "ppath = '/content/drive/MyDrive/SleepClass/Custom_Dataset_7'\n",
        "\n",
        "recordings = os.listdir(ppath)\n",
        "ndown = 4\n",
        "factor = 2500 #(time bin * sampling rate)\n",
        "recordings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGnR9Lhhu2p1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0c8631f-7c84-4575-d80b-3e8eabaa8165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recording c18_020418n1, eeg mean: -0.09729233593410916, eeg std: 43.51196222327882, emg mean: -0.09720869127909343, emg std: 49.475690164147714\n",
            "Recording c19_020418n1, eeg mean: -0.09741477436489529, eeg std: 69.04191819560756, emg mean: -0.09743111794259814, emg std: 44.777423211045765\n",
            "Recording c20_020618n1, eeg mean: -0.0974829969882965, eeg std: 58.803999630872745, emg mean: -0.09722581181526184, emg std: 52.670480132962005\n",
            "Recording c21_020618n1, eeg mean: -0.09715014465649922, eeg std: 73.09368704387148, emg mean: -0.09726402431594001, emg std: 47.56894731291857\n",
            "Recording c30_030418n1, eeg mean: -0.09653628292386494, eeg std: 88.5230110794834, emg mean: -0.09688220111301966, emg std: 46.44975305751588\n",
            "Recording J10_052318n1, eeg mean: -0.09689520683288574, eeg std: 93.24638709724168, emg mean: -0.0969138018714057, emg std: 91.32073252604764\n",
            "Recording J45_100918n1, eeg mean: -0.09748319424897238, eeg std: 107.63649720376205, emg mean: -0.09742848924624374, emg std: 60.96627993737547\n",
            "Recording J12_052818n1, eeg mean: -0.09756632244675248, eeg std: 90.7117119482564, emg mean: -0.09769658250455503, emg std: 52.898950421112964\n",
            "Recording J35_082118n1, eeg mean: -0.09704007222917345, eeg std: 93.5266194372923, emg mean: -0.09722458870675829, emg std: 48.76981456989392\n",
            "Recording J46_100918n1, eeg mean: -0.09693621252221998, eeg std: 92.7712221602342, emg mean: -0.09713032911712048, emg std: 54.74364902643321\n",
            "Recording J9_052318n1, eeg mean: -0.09744972172207303, eeg std: 73.66768040389704, emg mean: -0.09811940041436089, emg std: 76.97713580911596\n",
            "Recording c36_032518n1, eeg mean: -0.0964080929979866, eeg std: 66.20117991746248, emg mean: -0.09729710626013485, emg std: 56.81446476398425\n",
            "Recording J17_062618n1, eeg mean: -0.09749596502852223, eeg std: 80.712571210592, emg mean: -0.0975750590509184, emg std: 48.531142315945424\n",
            "Recording AC81_081221n1, eeg mean: -0.09738476211936385, eeg std: 74.97254880937658, emg mean: -0.0973060656176673, emg std: 60.186985256103505\n",
            "Recording AC85_082321n1, eeg mean: -0.09741829458872477, eeg std: 85.84854900435803, emg mean: -0.09731696831915114, emg std: 54.99688157377778\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "validation_split = 0.2\n",
        "\n",
        "training_data = []\n",
        "label_data = []\n",
        "\n",
        "EEG = np.array([])\n",
        "EMG = np.array([])\n",
        "M = np.array([])\n",
        "\n",
        "train_shape_repo = []\n",
        "test_shape_repo = []\n",
        "\n",
        "for name in recordings:\n",
        "  m = load_stateidx(ppath, name)[0]\n",
        "  m = m.astype('i')\n",
        "  m = m[:-1] # cut off the end that doesn't match\n",
        "  len_m = len(m)\n",
        "\n",
        "  eeg = so.loadmat(os.path.join(ppath, name, 'EEG.mat'), squeeze_me=True)['EEG']\n",
        "  eeg = eeg[:(len_m) * factor]    # truncate eeg length to the number of windows\n",
        "  eeg = sleepy.downsample_vec(eeg, ndown)\n",
        "  eeg = eeg.astype('float16')\n",
        "\n",
        "  emg = so.loadmat(os.path.join(ppath, name, 'EMG.mat'), squeeze_me=True)['EMG']\n",
        "  emg = emg[:(len_m) * factor]\n",
        "  emg = sleepy.downsample_vec(emg, ndown)\n",
        "  emg = emg.astype('float16')\n",
        "\n",
        "  # Change all the sleep states above 3 to NREM -- can change to separate out microarousals\n",
        "  for i in range(len(m)):\n",
        "    if m[i] > 3:\n",
        "      m[i] = 3\n",
        "    if m[i] == 0: # changed the unannotated segments to NREM\n",
        "      m[i] = 3\n",
        "\n",
        "  X = eeg\n",
        "  Y = m\n",
        "  Z = emg\n",
        "\n",
        "  # Do the test-validation set split\n",
        "  x_indices = list(range(len(X)))\n",
        "  y_indices = list(range(len(Y)))\n",
        "  # x_split = int(np.floor(validation_split * len(X)))\n",
        "  y_split = int(np.floor(validation_split * len(Y)))\n",
        "  x_split = y_split * int(factor/ndown+0.1)\n",
        "\n",
        "  x_train_indices, x_val_indices = x_indices[x_split:], x_indices[:x_split]\n",
        "  y_train_indices, y_val_indices = y_indices[y_split:], y_indices[:y_split]\n",
        "\n",
        "  x_train = X[x_train_indices].astype('<f8')\n",
        "  x_test = X[x_val_indices].astype('<f8')\n",
        "  z_train = Z[x_train_indices].astype('<f8')\n",
        "  z_test = Z[x_val_indices].astype('<f8')\n",
        "\n",
        "  ## Doing normalization for each recording independently\n",
        "  mean_x = np.nanmean(x_train)\n",
        "  std_x = np.nanstd(x_train)\n",
        "\n",
        "  x_train = ((x_train - mean_x) / std_x).astype('<f8')\n",
        "  x_test = ((x_test - mean_x) / std_x).astype('<f8')\n",
        "\n",
        "  mean_z = np.nanmean(z_train)\n",
        "  std_z = np.nanstd(z_train)\n",
        "\n",
        "  z_train = ((z_train - mean_z) / std_z).astype('<f8')\n",
        "  z_test = ((z_test - mean_z) / std_z).astype('<f8')\n",
        "\n",
        "\n",
        "  y_train = Y[y_train_indices].astype('int8')\n",
        "  y_test = Y[y_val_indices].astype('int8')\n",
        "\n",
        "\n",
        "  print(\"Recording {}, eeg mean: {}, eeg std: {}, emg mean: {}, emg std: {}\"\n",
        "          .format(name, mean_x, std_x, mean_z, std_z))\n",
        "\n",
        "  if (len(y_test) * 625 != len(x_test)) or (len(y_train) * 625!=len(x_train)):\n",
        "    print('Length error for', name)\n",
        "    False_flag = 1\n",
        "\n",
        "  EEG = np.append(EEG, x_train)\n",
        "  EMG = np.append(EMG, z_train)\n",
        "  M = np.append(M, y_train)\n",
        "\n",
        "  EEG = np.append(EEG, x_test)\n",
        "  EMG = np.append(EMG, z_test)\n",
        "  M = np.append(M, y_test)\n",
        "\n",
        "  train_shape_repo.append(y_train.shape[0])   ## save the dataset length of each recording for later use\n",
        "  test_shape_repo.append(y_test.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llgG_JKoGfH5"
      },
      "outputs": [],
      "source": [
        "M_upsampled = np.repeat(M, 625)\n",
        "\n",
        "input = np.vstack((EEG, EMG)).T\n",
        "\n",
        "window_size = 625\n",
        "input_size = 2\n",
        "dataset = CustomDataset(input, M_upsampled, window_size=window_size)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "biLSTM_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfL-6Rz4kpQN",
        "outputId": "512f61e4-2617-44a3-f667-6ac26538a851"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "biLSTM(\n",
              "  (lstm): LSTM(2, 128, num_layers=2, batch_first=True, dropout=0.1, bidirectional=True)\n",
              "  (fc): Sequential(\n",
              "    (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Linear(in_features=64, out_features=3, bias=True)\n",
              "  )\n",
              "  (softmax): Softmax(dim=1)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2lil1nIM4F96"
      },
      "outputs": [],
      "source": [
        "biLSTM_model.eval()\n",
        "predicted_labels = []\n",
        "real_labels = []\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "with torch.no_grad():\n",
        "  for iter, (input, target) in enumerate(loader):\n",
        "      input = input.to(device).double()\n",
        "      target = target.to(device).double()\n",
        "\n",
        "      output = biLSTM_model(input)\n",
        "\n",
        "      predicted_labels.extend(output.tolist())\n",
        "      real_labels.extend(target.tolist())\n",
        "\n",
        "predicted_labels = torch.tensor(predicted_labels)\n",
        "real_labels = torch.tensor(real_labels)\n",
        "\n",
        "val_output = F.one_hot(torch.max(predicted_labels, dim=1, keepdim=True)[1], num_classes = 3).squeeze()\n",
        "if val_output.dim() == 1:\n",
        "  predicted_classes = torch.argmax(val_output, dim=0)\n",
        "else:\n",
        "  predicted_classes = torch.argmax(val_output, dim=1)\n",
        "\n",
        "all_total = real_labels.size(0)   # the total number of dataset items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4JZBcQ1C-lr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d2454a1-4a77-408a-aaf4-63abf7c36af4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Subject: c18_020418n1 | biLSTM Accuracy: 89.49652777777777\n",
            "11470\n",
            "11470\n",
            "Test Subject: c19_020418n1 | biLSTM Accuracy: 90.21701388888889\n",
            "11470\n",
            "11470\n",
            "Test Subject: c20_020618n1 | biLSTM Accuracy: 91.31076388888889\n",
            "11470\n",
            "11470\n",
            "Test Subject: c21_020618n1 | biLSTM Accuracy: 89.28819444444444\n",
            "11470\n",
            "11470\n",
            "Test Subject: c30_030418n1 | biLSTM Accuracy: 89.24603174603175\n",
            "10030\n",
            "10030\n",
            "Test Subject: J10_052318n1 | biLSTM Accuracy: 92.09722222222223\n",
            "7150\n",
            "7150\n",
            "Test Subject: J45_100918n1 | biLSTM Accuracy: 88.33333333333333\n",
            "12190\n",
            "12190\n",
            "Test Subject: J12_052818n1 | biLSTM Accuracy: 89.13194444444444\n",
            "8590\n",
            "8590\n",
            "Test Subject: J35_082118n1 | biLSTM Accuracy: 91.30208333333333\n",
            "11470\n",
            "11470\n",
            "Test Subject: J46_100918n1 | biLSTM Accuracy: 88.48856209150327\n",
            "12190\n",
            "12190\n",
            "Test Subject: J9_052318n1 | biLSTM Accuracy: 88.68055555555556\n",
            "7150\n",
            "7150\n",
            "Test Subject: c36_032518n1 | biLSTM Accuracy: 60.6712962962963\n",
            "12910\n",
            "12910\n",
            "Test Subject: J17_062618n1 | biLSTM Accuracy: 89.95144789318536\n",
            "11484\n",
            "11484\n",
            "Test Subject: AC81_081221n1 | biLSTM Accuracy: 88.59085648148148\n",
            "34510\n",
            "34510\n",
            "Test Subject: AC85_082321n1 | biLSTM Accuracy: 89.51099537037037\n",
            "34510\n",
            "34510\n"
          ]
        }
      ],
      "source": [
        "for i, name in enumerate(recordings):\n",
        "\n",
        "  train_num = train_shape_repo[i]   # retrieve the number of train and test items in this recording\n",
        "  test_num = test_shape_repo[i]\n",
        "  train_total = int(np.sum(train_shape_repo)+0.1)\n",
        "\n",
        "  train_pre = int(np.sum(train_shape_repo[:i])+0.1)    # the previously already calculated index number in other recordings\n",
        "  test_pre = train_total + int(np.sum(test_shape_repo[:i])+0.1)\n",
        "\n",
        "  test_end_index = test_pre + test_num   # the test end index of selecting the current recording items\n",
        "  if test_end_index >= all_total:\n",
        "    test_end_index = None\n",
        "\n",
        "\n",
        "  test_correct = ((predicted_classes[train_pre:train_pre+train_num] == torch.argmax(real_labels, dim=1)[train_pre:train_pre+train_num]).sum().item()\n",
        "                 + (predicted_classes[test_pre:test_end_index] == torch.argmax(real_labels, dim=1)[test_pre:test_end_index]).sum().item())\n",
        "\n",
        "  test_session_total = train_num + test_num\n",
        "\n",
        "  test_session_acc = 100 * test_correct / test_session_total\n",
        "\n",
        "  print(\"Test Subject: {} | biLSTM Accuracy: {}\"\n",
        "          .format(name, test_session_acc))\n",
        "\n",
        "\n",
        "  ## Here to concate segments of 2nd stage data\n",
        "  segments = create_segments(torch.cat((predicted_labels[test_pre:test_end_index], predicted_labels[train_pre:train_pre+train_num]), dim=0),\n",
        "                            segment_length, overlap)\n",
        "\n",
        "  training_data.extend(segments)\n",
        "  print(len(segments))\n",
        "\n",
        "  # if test_end_index == None:    # change it to comply with test_end_index-idx\n",
        "  #   test_end_index = 0\n",
        "\n",
        "  idx = int(overlap/2)\n",
        "  labels = torch.cat((real_labels[idx+test_pre:test_end_index], real_labels[train_pre : train_pre+train_num - idx]), dim=0)\n",
        "\n",
        "  label_data.extend(labels)\n",
        "  print(len(labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW1jCrGtbLnq"
      },
      "source": [
        "# Stage 2: Fully Connected Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dnQrmHOQ9eF"
      },
      "outputs": [],
      "source": [
        "# Test-Train Split\n",
        "X = np.array(training_data)\n",
        "Y = np.array(label_data)\n",
        "\n",
        "x_train = []\n",
        "x_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "pointer = 0\n",
        "\n",
        "for i, _ in enumerate(train_shape_repo):\n",
        "  ## Doing normalization for each recording independently\n",
        "  pointer_temp = pointer + test_shape_repo[i] - idx\n",
        "  x_temp_train = X[pointer_temp:pointer_temp+train_shape_repo[i] - idx]\n",
        "  axis = (0, 2)   ## this is to ensure the same timepoint is divided by the same mean, while this mean is representing the whole trainig set\n",
        "  mean_x = np.nanmean(x_temp_train, axis=axis, keepdims=True)\n",
        "  std_x = np.nanstd(x_temp_train, axis=axis, keepdims=True)\n",
        "\n",
        "  x_temp_train = ((x_temp_train - mean_x) / std_x).astype('<f8')\n",
        "  x_temp_test = ((X[pointer:pointer+test_shape_repo[i] - idx] - mean_x) / std_x).astype('<f8')\n",
        "\n",
        "  x_test.extend(x_temp_test)\n",
        "  y_test.extend(Y[pointer:pointer+test_shape_repo[i] - idx])\n",
        "  pointer += test_shape_repo[i] - idx\n",
        "  x_train.extend(x_temp_train)\n",
        "  y_train.extend(Y[pointer:pointer+train_shape_repo[i] - idx])\n",
        "  pointer += train_shape_repo[i] - idx\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "x_test = np.array(x_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_example = x_test[:, 25]\n",
        "y_example = y_test\n",
        "correct = np.argmax(x_example, axis=1) == np.argmax(y_example, axis=1)\n",
        "total = len(x_example)\n",
        "correct.sum() / total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuJbhB-qBCtt",
        "outputId": "57659952-2c81-460f-d637-cfea3499be1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9057191871843816)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvy6VcqQKyus"
      },
      "outputs": [],
      "source": [
        "### Balancing AND normalization\n",
        "from scipy.special import softmax\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "rus = RandomUnderSampler(random_state=27)\n",
        "x_restrain, M_restrain = rus.fit_resample(x_train.reshape(len(np.argmax(y_train, axis=1)), -1), np.argmax(y_train, axis=1))\n",
        "x_restrain = x_restrain.reshape(-1, segment_length, 3)      # 3 for 3 sleep states\n",
        "y_restrain = np.eye(3)[M_restrain]\n",
        "\n",
        "def minmax_scale(x, axis=None):\n",
        "    min = np.min(x, axis=axis, keepdims=True)\n",
        "    max = np.max(x, axis=axis, keepdims=True)\n",
        "    result = (x-min)/(max-min)\n",
        "    return result\n",
        "\n",
        "def zscore_scale(x, axis=None):\n",
        "    mean = np.mean(x, axis=axis, keepdims=True)\n",
        "    std = np.std(x, axis=axis, keepdims=True)\n",
        "    std = np.where(std == 0, 1, std)\n",
        "    result = (x-mean)/std\n",
        "    return result\n",
        "\n",
        "# x_restrain = StandardScaler().fit_transform(x_restrain.reshape(len(x_restrain),-1)).reshape(-1, segment_length, 3)\n",
        "# x_test = StandardScaler().fit_transform(x_test.reshape(len(x_test),-1)).reshape(-1, segment_length, 3)\n",
        "\n",
        "# x_test = zscore_scale(x_test, axis=2)\n",
        "# x_restrain = zscore_scale(x_restrain, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "id": "QHoKu9q6TR44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0d543b3-ab2b-433f-c871-30e82a0dc336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(41387, 51, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_example = x_test[:, 25]\n",
        "y_example = y_test\n",
        "correct = np.argmax(x_example, axis=1) == np.argmax(y_example, axis=1)\n",
        "total = len(x_example)\n",
        "correct.sum() / total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPLFGu66A1Tb",
        "outputId": "1e9f49fd-699f-4f3b-ba66-d9c6d6293cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.9057191871843816)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_example = x_restrain[:, 25]\n",
        "y_example = y_restrain\n",
        "correct = np.argmax(x_example, axis=1) == np.argmax(y_example, axis=1)\n",
        "total = len(x_example)\n",
        "correct.sum() / total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWTIymRsCp5T",
        "outputId": "4e531cf9-05d0-4285-89b7-bcd080f05f51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.8723031740652886)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rdd3lLfPd54q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "314bec9f-4bce-4522-e189-235370e96bcf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.]], dtype=float32),\n",
              " array([97712, 57161, 11804]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "np.unique(y_train, axis=0, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0qfxnjFd78s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc34b1ed-13f1-47c3-870a-b043b7908f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0., 0., 1.],\n",
              "        [0., 1., 0.],\n",
              "        [1., 0., 0.]], dtype=float32),\n",
              " array([21323, 17345,  2719]))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "np.unique(y_test, axis=0, return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhPrlJWxePjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d270ea06-7c83-4595-c023-2967fa741eca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "y_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Q4-upfxNe7J"
      },
      "outputs": [],
      "source": [
        "class CustomDatasetFC(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = torch.tensor(data, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.int64)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.labels[index]\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vrLffyxEOKs6"
      },
      "outputs": [],
      "source": [
        "# Create custom datasets with normalized data\n",
        "\n",
        "train_dataset = CustomDatasetFC(x_restrain, y_restrain)\n",
        "test_dataset = CustomDatasetFC(x_test, y_test)\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plg56DUKQJYr"
      },
      "source": [
        "## Stage 2 Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvaCtCQzmGpJ",
        "outputId": "0b284bb4-fec0-4c31-ff9e-b570721c9500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.0+cu126\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Check that GPU is being used for model\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.__version__)\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJhjSoxLX0tb"
      },
      "outputs": [],
      "source": [
        "class FCNet(nn.Module):\n",
        "    def __init__(self, dropout=0.2):\n",
        "        super(FCNet, self).__init__()\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(segment_length * 3, 64), # ADD TO SEG LEGTH IF WE ARE LOOKING AT SPEC\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Linear(32, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Linear(32, 3),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # out = self.fc(x)\n",
        "        out = self.fc(x) + x[:,int((segment_length-1)/2+0.1)]   ## (segment_length-1)/2\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XeZvXoUNfdXO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecba7ff5-8406-434d-c2c5-18fe0f8b9732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FCNet(\n",
              "  (fc): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=153, out_features=64, bias=True)\n",
              "    (2): ReLU()\n",
              "    (3): Dropout(p=0.2, inplace=False)\n",
              "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
              "    (5): ReLU()\n",
              "    (6): Dropout(p=0.2, inplace=False)\n",
              "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (8): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (9): ReLU()\n",
              "    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Linear(in_features=32, out_features=3, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "FCNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G07wKd4mQObU"
      },
      "source": [
        "## Stage 2 Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c8f92ca-3173-4396-d9ca-07acd6fc7508",
        "id": "16EJKKNs9k9Y"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Runing training output distribution in this epoch:  [0.297 0.336 0.367]\n",
            "Runing training output distribution in this epoch:  [0.279 0.345 0.376]\n",
            "Runing training output distribution in this epoch:  [0.293 0.332 0.376]\n",
            "Runing training output distribution in this epoch:  [0.3   0.324 0.376]\n",
            "Runing training output distribution in this epoch:  [0.303 0.322 0.375]\n",
            "Runing training output distribution in this epoch:  [0.306 0.318 0.376]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.414 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.093 0.382 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.383 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.382 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.382 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.382 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.382 0.532]\n",
            "Epoch [1/100], Train Loss: 0.4916, Train Accuracy: 83.80%, Val Loss: 0.3191, Val Accuracy: 92.49%, F1 Score: 0.8976, AUC Score: 0.9437\n",
            "Runing training output distribution in this epoch:  [0.312 0.297 0.391]\n",
            "Runing training output distribution in this epoch:  [0.337 0.295 0.368]\n",
            "Runing training output distribution in this epoch:  [0.332 0.297 0.372]\n",
            "Runing training output distribution in this epoch:  [0.334 0.294 0.372]\n",
            "Runing training output distribution in this epoch:  [0.332 0.295 0.373]\n",
            "Runing training output distribution in this epoch:  [0.33  0.295 0.375]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.43  0.516]\n",
            "Runing testing output distribution in this epoch:  [0.09  0.382 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.38  0.532]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.383 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.383 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.528]\n",
            "Epoch [2/100], Train Loss: 0.4075, Train Accuracy: 87.29%, Val Loss: 0.2993, Val Accuracy: 92.74%, F1 Score: 0.9008, AUC Score: 0.9457\n",
            "Runing training output distribution in this epoch:  [0.281 0.305 0.414]\n",
            "Runing training output distribution in this epoch:  [0.333 0.291 0.376]\n",
            "Runing training output distribution in this epoch:  [0.329 0.289 0.382]\n",
            "Runing training output distribution in this epoch:  [0.331 0.289 0.38 ]\n",
            "Runing training output distribution in this epoch:  [0.333 0.292 0.375]\n",
            "Runing training output distribution in this epoch:  [0.335 0.291 0.374]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.414 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.38  0.535]\n",
            "Runing testing output distribution in this epoch:  [0.09  0.378 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.381 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.384 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.383 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.527]\n",
            "Epoch [3/100], Train Loss: 0.3715, Train Accuracy: 88.37%, Val Loss: 0.2877, Val Accuracy: 92.84%, F1 Score: 0.9021, AUC Score: 0.9463\n",
            "Runing training output distribution in this epoch:  [0.32  0.273 0.406]\n",
            "Runing training output distribution in this epoch:  [0.335 0.291 0.375]\n",
            "Runing training output distribution in this epoch:  [0.337 0.289 0.374]\n",
            "Runing training output distribution in this epoch:  [0.337 0.286 0.377]\n",
            "Runing training output distribution in this epoch:  [0.336 0.29  0.375]\n",
            "Runing training output distribution in this epoch:  [0.336 0.289 0.375]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.414 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.376 0.535]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.379 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.383 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.383 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.386 0.527]\n",
            "Epoch [4/100], Train Loss: 0.3518, Train Accuracy: 88.84%, Val Loss: 0.2771, Val Accuracy: 92.97%, F1 Score: 0.9034, AUC Score: 0.9472\n",
            "Runing training output distribution in this epoch:  [0.352 0.312 0.336]\n",
            "Runing training output distribution in this epoch:  [0.336 0.287 0.377]\n",
            "Runing training output distribution in this epoch:  [0.34  0.287 0.373]\n",
            "Runing training output distribution in this epoch:  [0.338 0.29  0.372]\n",
            "Runing training output distribution in this epoch:  [0.339 0.288 0.372]\n",
            "Runing training output distribution in this epoch:  [0.338 0.288 0.374]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.359 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.387 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.09  0.384 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.091 0.384 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.383 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.384 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.385 0.528]\n",
            "Epoch [5/100], Train Loss: 0.3367, Train Accuracy: 89.26%, Val Loss: 0.2705, Val Accuracy: 92.95%, F1 Score: 0.9033, AUC Score: 0.9471\n",
            "Runing training output distribution in this epoch:  [0.352 0.289 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.289 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.339 0.291 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.338 0.288 0.374]\n",
            "Runing training output distribution in this epoch:  [0.338 0.288 0.374]\n",
            "Runing training output distribution in this epoch:  [0.339 0.288 0.373]\n",
            "Runing testing output distribution in this epoch:  [0.133 0.336 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.383 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.383 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.387 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.386 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.387 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.386 0.528]\n",
            "Epoch [6/100], Train Loss: 0.3245, Train Accuracy: 89.54%, Val Loss: 0.2609, Val Accuracy: 93.12%, F1 Score: 0.9063, AUC Score: 0.9483\n",
            "Runing training output distribution in this epoch:  [0.352 0.281 0.367]\n",
            "Runing training output distribution in this epoch:  [0.345 0.282 0.372]\n",
            "Runing training output distribution in this epoch:  [0.34  0.288 0.372]\n",
            "Runing training output distribution in this epoch:  [0.338 0.289 0.373]\n",
            "Runing training output distribution in this epoch:  [0.339 0.289 0.372]\n",
            "Runing training output distribution in this epoch:  [0.34  0.287 0.372]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.391 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.38  0.532]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.382 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.383 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.384 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.386 0.528]\n",
            "Epoch [7/100], Train Loss: 0.3154, Train Accuracy: 89.74%, Val Loss: 0.2562, Val Accuracy: 93.17%, F1 Score: 0.9056, AUC Score: 0.9488\n",
            "Runing training output distribution in this epoch:  [0.43  0.203 0.367]\n",
            "Runing training output distribution in this epoch:  [0.346 0.284 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.282 0.378]\n",
            "Runing training output distribution in this epoch:  [0.34  0.284 0.375]\n",
            "Runing training output distribution in this epoch:  [0.338 0.287 0.374]\n",
            "Runing training output distribution in this epoch:  [0.341 0.286 0.373]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.453 0.445]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.392 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.388 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.386 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.384 0.529]\n",
            "Epoch [8/100], Train Loss: 0.3083, Train Accuracy: 89.93%, Val Loss: 0.2529, Val Accuracy: 93.26%, F1 Score: 0.9063, AUC Score: 0.9494\n",
            "Runing training output distribution in this epoch:  [0.352 0.227 0.422]\n",
            "Runing training output distribution in this epoch:  [0.341 0.283 0.377]\n",
            "Runing training output distribution in this epoch:  [0.338 0.286 0.376]\n",
            "Runing training output distribution in this epoch:  [0.34  0.285 0.375]\n",
            "Runing training output distribution in this epoch:  [0.342 0.283 0.374]\n",
            "Runing training output distribution in this epoch:  [0.342 0.286 0.372]\n",
            "Runing testing output distribution in this epoch:  [0.125 0.352 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.382 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.38  0.531]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.383 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.386 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.383 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.384 0.529]\n",
            "Epoch [9/100], Train Loss: 0.3011, Train Accuracy: 90.06%, Val Loss: 0.2463, Val Accuracy: 93.32%, F1 Score: 0.9077, AUC Score: 0.9499\n",
            "Runing training output distribution in this epoch:  [0.359 0.273 0.367]\n",
            "Runing training output distribution in this epoch:  [0.356 0.286 0.358]\n",
            "Runing training output distribution in this epoch:  [0.345 0.289 0.366]\n",
            "Runing training output distribution in this epoch:  [0.347 0.287 0.366]\n",
            "Runing training output distribution in this epoch:  [0.345 0.286 0.368]\n",
            "Runing training output distribution in this epoch:  [0.343 0.289 0.369]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.336 0.586]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.39  0.527]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.388 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.386 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.385 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.385 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.386 0.529]\n",
            "Epoch [10/100], Train Loss: 0.2934, Train Accuracy: 90.22%, Val Loss: 0.2431, Val Accuracy: 93.39%, F1 Score: 0.9103, AUC Score: 0.9503\n",
            "Runing training output distribution in this epoch:  [0.367 0.242 0.391]\n",
            "Runing training output distribution in this epoch:  [0.345 0.283 0.372]\n",
            "Runing training output distribution in this epoch:  [0.34  0.287 0.373]\n",
            "Runing training output distribution in this epoch:  [0.339 0.288 0.374]\n",
            "Runing training output distribution in this epoch:  [0.341 0.287 0.372]\n",
            "Runing training output distribution in this epoch:  [0.34  0.288 0.371]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.375 0.578]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.382 0.536]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.383 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.384 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.386 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.385 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.387 0.529]\n",
            "Epoch [11/100], Train Loss: 0.2914, Train Accuracy: 90.22%, Val Loss: 0.2342, Val Accuracy: 93.58%, F1 Score: 0.9137, AUC Score: 0.9519\n",
            "Runing training output distribution in this epoch:  [0.328 0.297 0.375]\n",
            "Runing training output distribution in this epoch:  [0.34  0.285 0.375]\n",
            "Runing training output distribution in this epoch:  [0.339 0.287 0.374]\n",
            "Runing training output distribution in this epoch:  [0.34 0.29 0.37]\n",
            "Runing training output distribution in this epoch:  [0.34  0.29  0.369]\n",
            "Runing training output distribution in this epoch:  [0.342 0.289 0.369]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.344 0.609]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.386 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.388 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.388 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.385 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.387 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.386 0.529]\n",
            "Epoch [12/100], Train Loss: 0.2864, Train Accuracy: 90.45%, Val Loss: 0.2349, Val Accuracy: 93.50%, F1 Score: 0.9115, AUC Score: 0.9514\n",
            "Runing training output distribution in this epoch:  [0.266 0.32  0.414]\n",
            "Runing training output distribution in this epoch:  [0.338 0.288 0.373]\n",
            "Runing training output distribution in this epoch:  [0.339 0.289 0.372]\n",
            "Runing training output distribution in this epoch:  [0.342 0.287 0.371]\n",
            "Runing training output distribution in this epoch:  [0.345 0.285 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.343 0.287 0.37 ]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.375 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.39  0.526]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.391 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.39  0.524]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.388 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.386 0.529]\n",
            "Epoch [13/100], Train Loss: 0.2812, Train Accuracy: 90.43%, Val Loss: 0.2324, Val Accuracy: 93.54%, F1 Score: 0.9124, AUC Score: 0.9514\n",
            "Runing training output distribution in this epoch:  [0.367 0.281 0.352]\n",
            "Runing training output distribution in this epoch:  [0.345 0.29  0.365]\n",
            "Runing training output distribution in this epoch:  [0.338 0.29  0.372]\n",
            "Runing training output distribution in this epoch:  [0.341 0.291 0.367]\n",
            "Runing training output distribution in this epoch:  [0.345 0.29  0.365]\n",
            "Runing training output distribution in this epoch:  [0.344 0.289 0.367]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.359 0.547]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.385 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.385 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.384 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.386 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Epoch [14/100], Train Loss: 0.2782, Train Accuracy: 90.52%, Val Loss: 0.2306, Val Accuracy: 93.58%, F1 Score: 0.9124, AUC Score: 0.9519\n",
            "Runing training output distribution in this epoch:  [0.398 0.227 0.375]\n",
            "Runing training output distribution in this epoch:  [0.35  0.284 0.366]\n",
            "Runing training output distribution in this epoch:  [0.345 0.288 0.367]\n",
            "Runing training output distribution in this epoch:  [0.344 0.288 0.368]\n",
            "Runing training output distribution in this epoch:  [0.342 0.29  0.369]\n",
            "Runing training output distribution in this epoch:  [0.34 0.29 0.37]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.453 0.445]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.396 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.385 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Epoch [15/100], Train Loss: 0.2753, Train Accuracy: 90.64%, Val Loss: 0.2264, Val Accuracy: 93.67%, F1 Score: 0.9150, AUC Score: 0.9526\n",
            "Runing training output distribution in this epoch:  [0.328 0.266 0.406]\n",
            "Runing training output distribution in this epoch:  [0.348 0.289 0.364]\n",
            "Runing training output distribution in this epoch:  [0.346 0.287 0.366]\n",
            "Runing training output distribution in this epoch:  [0.345 0.289 0.366]\n",
            "Runing training output distribution in this epoch:  [0.343 0.29  0.366]\n",
            "Runing training output distribution in this epoch:  [0.342 0.29  0.368]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.383 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.381 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.384 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.388 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.387 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.529]\n",
            "Epoch [16/100], Train Loss: 0.2716, Train Accuracy: 90.63%, Val Loss: 0.2213, Val Accuracy: 93.77%, F1 Score: 0.9167, AUC Score: 0.9530\n",
            "Runing training output distribution in this epoch:  [0.312 0.312 0.375]\n",
            "Runing training output distribution in this epoch:  [0.341 0.289 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.295 0.364]\n",
            "Runing training output distribution in this epoch:  [0.343 0.292 0.365]\n",
            "Runing training output distribution in this epoch:  [0.344 0.289 0.367]\n",
            "Runing training output distribution in this epoch:  [0.342 0.29  0.367]\n",
            "Runing testing output distribution in this epoch:  [0.109 0.383 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.09  0.385 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.388 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.389 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.389 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.387 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.387 0.528]\n",
            "Epoch [17/100], Train Loss: 0.2691, Train Accuracy: 90.77%, Val Loss: 0.2210, Val Accuracy: 93.71%, F1 Score: 0.9140, AUC Score: 0.9529\n",
            "Runing training output distribution in this epoch:  [0.406 0.25  0.344]\n",
            "Runing training output distribution in this epoch:  [0.341 0.285 0.374]\n",
            "Runing training output distribution in this epoch:  [0.346 0.286 0.367]\n",
            "Runing training output distribution in this epoch:  [0.347 0.289 0.364]\n",
            "Runing training output distribution in this epoch:  [0.345 0.289 0.366]\n",
            "Runing training output distribution in this epoch:  [0.344 0.289 0.367]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.367 0.586]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.387 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.389 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Epoch [18/100], Train Loss: 0.2671, Train Accuracy: 90.81%, Val Loss: 0.2204, Val Accuracy: 93.76%, F1 Score: 0.9140, AUC Score: 0.9531\n",
            "Runing training output distribution in this epoch:  [0.328 0.336 0.336]\n",
            "Runing training output distribution in this epoch:  [0.333 0.3   0.368]\n",
            "Runing training output distribution in this epoch:  [0.337 0.297 0.365]\n",
            "Runing training output distribution in this epoch:  [0.339 0.296 0.365]\n",
            "Runing training output distribution in this epoch:  [0.339 0.294 0.367]\n",
            "Runing training output distribution in this epoch:  [0.341 0.292 0.367]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.398 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.384 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.385 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.387 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.387 0.529]\n",
            "Epoch [19/100], Train Loss: 0.2646, Train Accuracy: 90.88%, Val Loss: 0.2123, Val Accuracy: 93.92%, F1 Score: 0.9179, AUC Score: 0.9544\n",
            "Runing training output distribution in this epoch:  [0.266 0.32  0.414]\n",
            "Runing training output distribution in this epoch:  [0.332 0.292 0.376]\n",
            "Runing training output distribution in this epoch:  [0.335 0.294 0.37 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.292 0.369]\n",
            "Runing training output distribution in this epoch:  [0.341 0.293 0.366]\n",
            "Runing training output distribution in this epoch:  [0.342 0.293 0.365]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.367 0.57 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.388 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.385 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.388 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.389 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Epoch [20/100], Train Loss: 0.2615, Train Accuracy: 90.99%, Val Loss: 0.2152, Val Accuracy: 93.90%, F1 Score: 0.9177, AUC Score: 0.9542\n",
            "Runing training output distribution in this epoch:  [0.359 0.273 0.367]\n",
            "Runing training output distribution in this epoch:  [0.344 0.293 0.363]\n",
            "Runing training output distribution in this epoch:  [0.34  0.294 0.366]\n",
            "Runing training output distribution in this epoch:  [0.339 0.295 0.366]\n",
            "Runing training output distribution in this epoch:  [0.34  0.294 0.366]\n",
            "Runing training output distribution in this epoch:  [0.341 0.294 0.365]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.414 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.388 0.534]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.386 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.385 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.387 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.389 0.528]\n",
            "Epoch [21/100], Train Loss: 0.2609, Train Accuracy: 91.00%, Val Loss: 0.2098, Val Accuracy: 94.02%, F1 Score: 0.9200, AUC Score: 0.9552\n",
            "Runing training output distribution in this epoch:  [0.297 0.234 0.469]\n",
            "Runing training output distribution in this epoch:  [0.331 0.297 0.371]\n",
            "Runing training output distribution in this epoch:  [0.338 0.295 0.367]\n",
            "Runing training output distribution in this epoch:  [0.339 0.295 0.366]\n",
            "Runing training output distribution in this epoch:  [0.339 0.296 0.365]\n",
            "Runing training output distribution in this epoch:  [0.341 0.294 0.365]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.375 0.547]\n",
            "Runing testing output distribution in this epoch:  [0.077 0.39  0.533]\n",
            "Runing testing output distribution in this epoch:  [0.077 0.393 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.392 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.39  0.526]\n",
            "Epoch [22/100], Train Loss: 0.2605, Train Accuracy: 91.08%, Val Loss: 0.2098, Val Accuracy: 94.06%, F1 Score: 0.9186, AUC Score: 0.9553\n",
            "Runing training output distribution in this epoch:  [0.383 0.258 0.359]\n",
            "Runing training output distribution in this epoch:  [0.337 0.294 0.369]\n",
            "Runing training output distribution in this epoch:  [0.34  0.294 0.366]\n",
            "Runing training output distribution in this epoch:  [0.34  0.296 0.363]\n",
            "Runing training output distribution in this epoch:  [0.342 0.295 0.363]\n",
            "Runing training output distribution in this epoch:  [0.343 0.293 0.364]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.422 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.391 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.387 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.386 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.387 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.527]\n",
            "Epoch [23/100], Train Loss: 0.2586, Train Accuracy: 91.04%, Val Loss: 0.2101, Val Accuracy: 94.06%, F1 Score: 0.9189, AUC Score: 0.9554\n",
            "Runing training output distribution in this epoch:  [0.367 0.266 0.367]\n",
            "Runing training output distribution in this epoch:  [0.347 0.29  0.363]\n",
            "Runing training output distribution in this epoch:  [0.347 0.289 0.364]\n",
            "Runing training output distribution in this epoch:  [0.347 0.289 0.364]\n",
            "Runing training output distribution in this epoch:  [0.343 0.291 0.366]\n",
            "Runing training output distribution in this epoch:  [0.342 0.293 0.365]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.422 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.393 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.388 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.389 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.386 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.389 0.528]\n",
            "Epoch [24/100], Train Loss: 0.2573, Train Accuracy: 91.23%, Val Loss: 0.2071, Val Accuracy: 94.05%, F1 Score: 0.9191, AUC Score: 0.9555\n",
            "Runing training output distribution in this epoch:  [0.391 0.297 0.312]\n",
            "Runing training output distribution in this epoch:  [0.347 0.292 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.345 0.291 0.363]\n",
            "Runing training output distribution in this epoch:  [0.347 0.291 0.363]\n",
            "Runing training output distribution in this epoch:  [0.344 0.293 0.363]\n",
            "Runing training output distribution in this epoch:  [0.342 0.294 0.363]\n",
            "Runing testing output distribution in this epoch:  [0.039 0.461 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.388 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.39  0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.391 0.525]\n",
            "Epoch [25/100], Train Loss: 0.2551, Train Accuracy: 91.25%, Val Loss: 0.2075, Val Accuracy: 94.12%, F1 Score: 0.9204, AUC Score: 0.9560\n",
            "Runing training output distribution in this epoch:  [0.398 0.281 0.32 ]\n",
            "Runing training output distribution in this epoch:  [0.353 0.291 0.357]\n",
            "Runing training output distribution in this epoch:  [0.343 0.292 0.364]\n",
            "Runing training output distribution in this epoch:  [0.341 0.295 0.364]\n",
            "Runing training output distribution in this epoch:  [0.344 0.293 0.363]\n",
            "Runing training output distribution in this epoch:  [0.343 0.295 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.414 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.391 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.391 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.39  0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.39  0.526]\n",
            "Epoch [26/100], Train Loss: 0.2532, Train Accuracy: 91.22%, Val Loss: 0.2054, Val Accuracy: 94.14%, F1 Score: 0.9191, AUC Score: 0.9560\n",
            "Runing training output distribution in this epoch:  [0.406 0.25  0.344]\n",
            "Runing training output distribution in this epoch:  [0.342 0.295 0.362]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.362]\n",
            "Runing training output distribution in this epoch:  [0.341 0.296 0.363]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.362]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.406 0.477]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.397 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.395 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.39  0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.39  0.527]\n",
            "Epoch [27/100], Train Loss: 0.2526, Train Accuracy: 91.33%, Val Loss: 0.2006, Val Accuracy: 94.21%, F1 Score: 0.9215, AUC Score: 0.9566\n",
            "Runing training output distribution in this epoch:  [0.398 0.266 0.336]\n",
            "Runing training output distribution in this epoch:  [0.347 0.295 0.358]\n",
            "Runing training output distribution in this epoch:  [0.347 0.295 0.359]\n",
            "Runing training output distribution in this epoch:  [0.343 0.295 0.362]\n",
            "Runing training output distribution in this epoch:  [0.344 0.296 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.344 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.394 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.525]\n",
            "Epoch [28/100], Train Loss: 0.2513, Train Accuracy: 91.32%, Val Loss: 0.2005, Val Accuracy: 94.23%, F1 Score: 0.9227, AUC Score: 0.9568\n",
            "Runing training output distribution in this epoch:  [0.336 0.312 0.352]\n",
            "Runing training output distribution in this epoch:  [0.34  0.298 0.362]\n",
            "Runing training output distribution in this epoch:  [0.339 0.295 0.365]\n",
            "Runing training output distribution in this epoch:  [0.339 0.296 0.365]\n",
            "Runing training output distribution in this epoch:  [0.339 0.297 0.364]\n",
            "Runing training output distribution in this epoch:  [0.342 0.295 0.363]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.398 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Epoch [29/100], Train Loss: 0.2515, Train Accuracy: 91.24%, Val Loss: 0.1998, Val Accuracy: 94.26%, F1 Score: 0.9219, AUC Score: 0.9570\n",
            "Runing training output distribution in this epoch:  [0.344 0.281 0.375]\n",
            "Runing training output distribution in this epoch:  [0.347 0.29  0.363]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.361]\n",
            "Runing training output distribution in this epoch:  [0.345 0.293 0.362]\n",
            "Runing training output distribution in this epoch:  [0.343 0.295 0.362]\n",
            "Runing training output distribution in this epoch:  [0.342 0.296 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.445 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.389 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.388 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Epoch [30/100], Train Loss: 0.2508, Train Accuracy: 91.34%, Val Loss: 0.1989, Val Accuracy: 94.23%, F1 Score: 0.9212, AUC Score: 0.9567\n",
            "Runing training output distribution in this epoch:  [0.383 0.25  0.367]\n",
            "Runing training output distribution in this epoch:  [0.337 0.292 0.371]\n",
            "Runing training output distribution in this epoch:  [0.342 0.294 0.363]\n",
            "Runing training output distribution in this epoch:  [0.342 0.296 0.362]\n",
            "Runing training output distribution in this epoch:  [0.342 0.296 0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.297 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.422 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.382 0.532]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.388 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.388 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Epoch [31/100], Train Loss: 0.2498, Train Accuracy: 91.35%, Val Loss: 0.1943, Val Accuracy: 94.27%, F1 Score: 0.9232, AUC Score: 0.9571\n",
            "Runing training output distribution in this epoch:  [0.453 0.258 0.289]\n",
            "Runing training output distribution in this epoch:  [0.337 0.3   0.362]\n",
            "Runing training output distribution in this epoch:  [0.34 0.3  0.36]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.298 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.398 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.394 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.393 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.394 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.391 0.528]\n",
            "Epoch [32/100], Train Loss: 0.2496, Train Accuracy: 91.32%, Val Loss: 0.1915, Val Accuracy: 94.38%, F1 Score: 0.9242, AUC Score: 0.9578\n",
            "Runing training output distribution in this epoch:  [0.305 0.297 0.398]\n",
            "Runing training output distribution in this epoch:  [0.336 0.301 0.363]\n",
            "Runing training output distribution in this epoch:  [0.339 0.297 0.364]\n",
            "Runing training output distribution in this epoch:  [0.339 0.296 0.365]\n",
            "Runing training output distribution in this epoch:  [0.34  0.297 0.363]\n",
            "Runing training output distribution in this epoch:  [0.342 0.296 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.398 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.404 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.394 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.393 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Epoch [33/100], Train Loss: 0.2473, Train Accuracy: 91.40%, Val Loss: 0.1945, Val Accuracy: 94.35%, F1 Score: 0.9235, AUC Score: 0.9576\n",
            "Runing training output distribution in this epoch:  [0.305 0.344 0.352]\n",
            "Runing training output distribution in this epoch:  [0.344 0.299 0.356]\n",
            "Runing training output distribution in this epoch:  [0.345 0.297 0.358]\n",
            "Runing training output distribution in this epoch:  [0.339 0.299 0.362]\n",
            "Runing training output distribution in this epoch:  [0.339 0.3   0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.414 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.392 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.392 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.393 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.529]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Epoch [34/100], Train Loss: 0.2463, Train Accuracy: 91.42%, Val Loss: 0.1952, Val Accuracy: 94.29%, F1 Score: 0.9227, AUC Score: 0.9571\n",
            "Runing training output distribution in this epoch:  [0.391 0.297 0.312]\n",
            "Runing training output distribution in this epoch:  [0.335 0.303 0.362]\n",
            "Runing training output distribution in this epoch:  [0.336 0.302 0.362]\n",
            "Runing training output distribution in this epoch:  [0.336 0.301 0.363]\n",
            "Runing training output distribution in this epoch:  [0.34  0.298 0.362]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.422 0.477]\n",
            "Runing testing output distribution in this epoch:  [0.089 0.388 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Epoch [35/100], Train Loss: 0.2453, Train Accuracy: 91.45%, Val Loss: 0.1970, Val Accuracy: 94.40%, F1 Score: 0.9235, AUC Score: 0.9580\n",
            "Runing training output distribution in this epoch:  [0.328 0.266 0.406]\n",
            "Runing training output distribution in this epoch:  [0.345 0.297 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.3   0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.362]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.469 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.077 0.4   0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.525]\n",
            "Epoch [36/100], Train Loss: 0.2438, Train Accuracy: 91.57%, Val Loss: 0.1921, Val Accuracy: 94.38%, F1 Score: 0.9237, AUC Score: 0.9578\n",
            "Runing training output distribution in this epoch:  [0.359 0.312 0.328]\n",
            "Runing training output distribution in this epoch:  [0.345 0.298 0.357]\n",
            "Runing training output distribution in this epoch:  [0.348 0.294 0.358]\n",
            "Runing training output distribution in this epoch:  [0.345 0.296 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.359 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.403 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.393 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.527]\n",
            "Epoch [37/100], Train Loss: 0.2449, Train Accuracy: 91.51%, Val Loss: 0.1909, Val Accuracy: 94.40%, F1 Score: 0.9242, AUC Score: 0.9580\n",
            "Runing training output distribution in this epoch:  [0.352 0.305 0.344]\n",
            "Runing training output distribution in this epoch:  [0.337 0.303 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.343 0.299 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.299 0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.362]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.352 0.602]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.384 0.534]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.389 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.39  0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Epoch [38/100], Train Loss: 0.2447, Train Accuracy: 91.45%, Val Loss: 0.1915, Val Accuracy: 94.46%, F1 Score: 0.9235, AUC Score: 0.9584\n",
            "Runing training output distribution in this epoch:  [0.367 0.289 0.344]\n",
            "Runing training output distribution in this epoch:  [0.334 0.3   0.366]\n",
            "Runing training output distribution in this epoch:  [0.333 0.303 0.364]\n",
            "Runing training output distribution in this epoch:  [0.338 0.301 0.362]\n",
            "Runing training output distribution in this epoch:  [0.339 0.3   0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.299 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.109 0.328 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.384 0.536]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.389 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.388 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.526]\n",
            "Epoch [39/100], Train Loss: 0.2436, Train Accuracy: 91.51%, Val Loss: 0.1892, Val Accuracy: 94.47%, F1 Score: 0.9247, AUC Score: 0.9585\n",
            "Runing training output distribution in this epoch:  [0.281 0.352 0.367]\n",
            "Runing training output distribution in this epoch:  [0.344 0.293 0.363]\n",
            "Runing training output distribution in this epoch:  [0.344 0.298 0.359]\n",
            "Runing training output distribution in this epoch:  [0.34 0.3  0.36]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.36 ]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.414 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.39  0.522]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Epoch [40/100], Train Loss: 0.2415, Train Accuracy: 91.60%, Val Loss: 0.1900, Val Accuracy: 94.51%, F1 Score: 0.9249, AUC Score: 0.9588\n",
            "Runing training output distribution in this epoch:  [0.352 0.305 0.344]\n",
            "Runing training output distribution in this epoch:  [0.336 0.307 0.357]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.356]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.453 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.399 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Epoch [41/100], Train Loss: 0.2414, Train Accuracy: 91.64%, Val Loss: 0.1893, Val Accuracy: 94.51%, F1 Score: 0.9254, AUC Score: 0.9588\n",
            "Runing training output distribution in this epoch:  [0.398 0.305 0.297]\n",
            "Runing training output distribution in this epoch:  [0.347 0.295 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.361]\n",
            "Runing training output distribution in this epoch:  [0.344 0.298 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.125 0.336 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.388 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.388 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.389 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Epoch [42/100], Train Loss: 0.2415, Train Accuracy: 91.62%, Val Loss: 0.1868, Val Accuracy: 94.52%, F1 Score: 0.9256, AUC Score: 0.9589\n",
            "Runing training output distribution in this epoch:  [0.289 0.281 0.43 ]\n",
            "Runing training output distribution in this epoch:  [0.347 0.288 0.365]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.344 0.297 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.344 0.296 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.438 0.445]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.396 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Epoch [43/100], Train Loss: 0.2403, Train Accuracy: 91.61%, Val Loss: 0.1865, Val Accuracy: 94.51%, F1 Score: 0.9253, AUC Score: 0.9588\n",
            "Runing training output distribution in this epoch:  [0.414 0.266 0.32 ]\n",
            "Runing training output distribution in this epoch:  [0.339 0.304 0.357]\n",
            "Runing training output distribution in this epoch:  [0.338 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.338 0.302 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.338 0.302 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.339 0.302 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.32  0.625]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.409 0.512]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.402 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.397 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [44/100], Train Loss: 0.2392, Train Accuracy: 91.66%, Val Loss: 0.1891, Val Accuracy: 94.56%, F1 Score: 0.9262, AUC Score: 0.9592\n",
            "Runing training output distribution in this epoch:  [0.406 0.273 0.32 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.363]\n",
            "Runing training output distribution in this epoch:  [0.336 0.301 0.362]\n",
            "Runing training output distribution in this epoch:  [0.338 0.302 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.391 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.399 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.391 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Epoch [45/100], Train Loss: 0.2393, Train Accuracy: 91.68%, Val Loss: 0.1821, Val Accuracy: 94.59%, F1 Score: 0.9264, AUC Score: 0.9595\n",
            "Runing training output distribution in this epoch:  [0.273 0.289 0.438]\n",
            "Runing training output distribution in this epoch:  [0.335 0.302 0.363]\n",
            "Runing training output distribution in this epoch:  [0.337 0.302 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.299 0.361]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.445 0.492]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Epoch [46/100], Train Loss: 0.2392, Train Accuracy: 91.64%, Val Loss: 0.1830, Val Accuracy: 94.57%, F1 Score: 0.9259, AUC Score: 0.9592\n",
            "Runing training output distribution in this epoch:  [0.375 0.273 0.352]\n",
            "Runing training output distribution in this epoch:  [0.337 0.299 0.364]\n",
            "Runing training output distribution in this epoch:  [0.339 0.297 0.364]\n",
            "Runing training output distribution in this epoch:  [0.338 0.299 0.363]\n",
            "Runing training output distribution in this epoch:  [0.34  0.3   0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.422 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.396 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.523]\n",
            "Epoch [47/100], Train Loss: 0.2401, Train Accuracy: 91.67%, Val Loss: 0.1834, Val Accuracy: 94.60%, F1 Score: 0.9269, AUC Score: 0.9595\n",
            "Runing training output distribution in this epoch:  [0.32  0.336 0.344]\n",
            "Runing training output distribution in this epoch:  [0.348 0.302 0.351]\n",
            "Runing training output distribution in this epoch:  [0.347 0.298 0.355]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.299 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.367 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.395 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Epoch [48/100], Train Loss: 0.2383, Train Accuracy: 91.78%, Val Loss: 0.1871, Val Accuracy: 94.54%, F1 Score: 0.9230, AUC Score: 0.9591\n",
            "Runing training output distribution in this epoch:  [0.391 0.242 0.367]\n",
            "Runing training output distribution in this epoch:  [0.344 0.296 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.339 0.299 0.362]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.438 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.525]\n",
            "Epoch [49/100], Train Loss: 0.2402, Train Accuracy: 91.65%, Val Loss: 0.1855, Val Accuracy: 94.60%, F1 Score: 0.9254, AUC Score: 0.9595\n",
            "Runing training output distribution in this epoch:  [0.352 0.273 0.375]\n",
            "Runing training output distribution in this epoch:  [0.346 0.301 0.353]\n",
            "Runing training output distribution in this epoch:  [0.339 0.301 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.383 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.08 0.39 0.53]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.395 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.397 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.396 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Epoch [50/100], Train Loss: 0.2376, Train Accuracy: 91.82%, Val Loss: 0.1830, Val Accuracy: 94.63%, F1 Score: 0.9265, AUC Score: 0.9598\n",
            "Runing training output distribution in this epoch:  [0.312 0.352 0.336]\n",
            "Runing training output distribution in this epoch:  [0.342 0.297 0.361]\n",
            "Runing training output distribution in this epoch:  [0.343 0.3   0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.299 0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.039 0.438 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Epoch [51/100], Train Loss: 0.2373, Train Accuracy: 91.67%, Val Loss: 0.1868, Val Accuracy: 94.57%, F1 Score: 0.9248, AUC Score: 0.9593\n",
            "Runing training output distribution in this epoch:  [0.367 0.273 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.301 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.305 0.355]\n",
            "Runing training output distribution in this epoch:  [0.342 0.304 0.354]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.355]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.469 0.461]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.401 0.513]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.397 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.524]\n",
            "Epoch [52/100], Train Loss: 0.2373, Train Accuracy: 91.73%, Val Loss: 0.1835, Val Accuracy: 94.66%, F1 Score: 0.9273, AUC Score: 0.9599\n",
            "Runing training output distribution in this epoch:  [0.336 0.328 0.336]\n",
            "Runing training output distribution in this epoch:  [0.343 0.298 0.359]\n",
            "Runing training output distribution in this epoch:  [0.338 0.303 0.359]\n",
            "Runing training output distribution in this epoch:  [0.337 0.304 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.359]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.438 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.076 0.401 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Epoch [53/100], Train Loss: 0.2356, Train Accuracy: 91.79%, Val Loss: 0.1836, Val Accuracy: 94.63%, F1 Score: 0.9266, AUC Score: 0.9597\n",
            "Runing training output distribution in this epoch:  [0.336 0.305 0.359]\n",
            "Runing training output distribution in this epoch:  [0.336 0.302 0.362]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.344 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.382 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.386 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.39  0.528]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Epoch [54/100], Train Loss: 0.2357, Train Accuracy: 91.82%, Val Loss: 0.1788, Val Accuracy: 94.68%, F1 Score: 0.9282, AUC Score: 0.9601\n",
            "Runing training output distribution in this epoch:  [0.375 0.312 0.312]\n",
            "Runing training output distribution in this epoch:  [0.346 0.3   0.353]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.354]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.354]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.336 0.57 ]\n",
            "Runing testing output distribution in this epoch:  [0.08 0.4  0.52]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.401 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.524]\n",
            "Epoch [55/100], Train Loss: 0.2353, Train Accuracy: 91.83%, Val Loss: 0.1836, Val Accuracy: 94.65%, F1 Score: 0.9261, AUC Score: 0.9599\n",
            "Runing training output distribution in this epoch:  [0.352 0.258 0.391]\n",
            "Runing training output distribution in this epoch:  [0.341 0.295 0.364]\n",
            "Runing training output distribution in this epoch:  [0.343 0.299 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.398 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.388 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.391 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.397 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.397 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.397 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Epoch [56/100], Train Loss: 0.2365, Train Accuracy: 91.75%, Val Loss: 0.1837, Val Accuracy: 94.62%, F1 Score: 0.9264, AUC Score: 0.9596\n",
            "Runing training output distribution in this epoch:  [0.336 0.273 0.391]\n",
            "Runing training output distribution in this epoch:  [0.333 0.308 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.337 0.302 0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.367 0.578]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.402 0.512]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.403 0.514]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.401 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Epoch [57/100], Train Loss: 0.2351, Train Accuracy: 91.81%, Val Loss: 0.1851, Val Accuracy: 94.64%, F1 Score: 0.9254, AUC Score: 0.9598\n",
            "Runing training output distribution in this epoch:  [0.359 0.258 0.383]\n",
            "Runing training output distribution in this epoch:  [0.349 0.299 0.352]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.414 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.392 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Epoch [58/100], Train Loss: 0.2341, Train Accuracy: 91.89%, Val Loss: 0.1817, Val Accuracy: 94.69%, F1 Score: 0.9276, AUC Score: 0.9602\n",
            "Runing training output distribution in this epoch:  [0.336 0.266 0.398]\n",
            "Runing training output distribution in this epoch:  [0.338 0.298 0.364]\n",
            "Runing training output distribution in this epoch:  [0.336 0.298 0.366]\n",
            "Runing training output distribution in this epoch:  [0.339 0.297 0.364]\n",
            "Runing training output distribution in this epoch:  [0.339 0.3   0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.383 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.381 0.533]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.387 0.53 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Epoch [59/100], Train Loss: 0.2348, Train Accuracy: 91.80%, Val Loss: 0.1809, Val Accuracy: 94.66%, F1 Score: 0.9263, AUC Score: 0.9599\n",
            "Runing training output distribution in this epoch:  [0.391 0.336 0.273]\n",
            "Runing training output distribution in this epoch:  [0.348 0.295 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.298 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.298 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.299 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.367 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.389 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.389 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Epoch [60/100], Train Loss: 0.2346, Train Accuracy: 91.80%, Val Loss: 0.1816, Val Accuracy: 94.66%, F1 Score: 0.9259, AUC Score: 0.9601\n",
            "Runing training output distribution in this epoch:  [0.32  0.336 0.344]\n",
            "Runing training output distribution in this epoch:  [0.35  0.299 0.35 ]\n",
            "Runing training output distribution in this epoch:  [0.345 0.301 0.353]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.355]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.359 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.391 0.527]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.392 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Epoch [61/100], Train Loss: 0.2333, Train Accuracy: 91.90%, Val Loss: 0.1831, Val Accuracy: 94.63%, F1 Score: 0.9262, AUC Score: 0.9597\n",
            "Runing training output distribution in this epoch:  [0.359 0.297 0.344]\n",
            "Runing training output distribution in this epoch:  [0.335 0.306 0.359]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.299 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.339 0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.344 0.57 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.394 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Epoch [62/100], Train Loss: 0.2332, Train Accuracy: 91.79%, Val Loss: 0.1837, Val Accuracy: 94.66%, F1 Score: 0.9272, AUC Score: 0.9599\n",
            "Runing training output distribution in this epoch:  [0.359 0.328 0.312]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.338 0.302 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.339 0.302 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.398 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.392 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.399 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.395 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Epoch [63/100], Train Loss: 0.2321, Train Accuracy: 91.82%, Val Loss: 0.1789, Val Accuracy: 94.74%, F1 Score: 0.9281, AUC Score: 0.9606\n",
            "Runing training output distribution in this epoch:  [0.344 0.305 0.352]\n",
            "Runing training output distribution in this epoch:  [0.351 0.3   0.348]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.355]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.43  0.508]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.396 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [64/100], Train Loss: 0.2335, Train Accuracy: 91.94%, Val Loss: 0.1828, Val Accuracy: 94.70%, F1 Score: 0.9265, AUC Score: 0.9603\n",
            "Runing training output distribution in this epoch:  [0.219 0.312 0.469]\n",
            "Runing training output distribution in this epoch:  [0.336 0.3   0.364]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.343 0.301 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.352 0.547]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.395 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.398 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.523]\n",
            "Epoch [65/100], Train Loss: 0.2316, Train Accuracy: 91.94%, Val Loss: 0.1818, Val Accuracy: 94.65%, F1 Score: 0.9249, AUC Score: 0.9599\n",
            "Runing training output distribution in this epoch:  [0.344 0.234 0.422]\n",
            "Runing training output distribution in this epoch:  [0.346 0.301 0.353]\n",
            "Runing training output distribution in this epoch:  [0.344 0.303 0.354]\n",
            "Runing training output distribution in this epoch:  [0.342 0.303 0.355]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.32  0.633]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.39  0.527]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.39  0.525]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.391 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Epoch [66/100], Train Loss: 0.2320, Train Accuracy: 91.78%, Val Loss: 0.1801, Val Accuracy: 94.71%, F1 Score: 0.9268, AUC Score: 0.9604\n",
            "Runing training output distribution in this epoch:  [0.336 0.305 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.306 0.354]\n",
            "Runing training output distribution in this epoch:  [0.344 0.301 0.354]\n",
            "Runing training output distribution in this epoch:  [0.344 0.301 0.355]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.398 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.403 0.513]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.394 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.396 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.397 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Epoch [67/100], Train Loss: 0.2330, Train Accuracy: 91.95%, Val Loss: 0.1807, Val Accuracy: 94.70%, F1 Score: 0.9265, AUC Score: 0.9603\n",
            "Runing training output distribution in this epoch:  [0.359 0.336 0.305]\n",
            "Runing training output distribution in this epoch:  [0.342 0.307 0.351]\n",
            "Runing training output distribution in this epoch:  [0.337 0.31  0.353]\n",
            "Runing training output distribution in this epoch:  [0.337 0.309 0.355]\n",
            "Runing training output distribution in this epoch:  [0.339 0.306 0.355]\n",
            "Runing training output distribution in this epoch:  [0.341 0.304 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.359 0.562]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.402 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.396 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Epoch [68/100], Train Loss: 0.2331, Train Accuracy: 91.92%, Val Loss: 0.1782, Val Accuracy: 94.72%, F1 Score: 0.9271, AUC Score: 0.9603\n",
            "Runing training output distribution in this epoch:  [0.312 0.336 0.352]\n",
            "Runing training output distribution in this epoch:  [0.325 0.301 0.374]\n",
            "Runing training output distribution in this epoch:  [0.337 0.299 0.364]\n",
            "Runing training output distribution in this epoch:  [0.339 0.302 0.359]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.352 0.594]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Epoch [69/100], Train Loss: 0.2309, Train Accuracy: 91.94%, Val Loss: 0.1803, Val Accuracy: 94.77%, F1 Score: 0.9276, AUC Score: 0.9608\n",
            "Runing training output distribution in this epoch:  [0.312 0.273 0.414]\n",
            "Runing training output distribution in this epoch:  [0.345 0.3   0.355]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.353]\n",
            "Runing training output distribution in this epoch:  [0.342 0.305 0.353]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.354]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.133 0.469 0.398]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.392 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.392 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [70/100], Train Loss: 0.2315, Train Accuracy: 91.90%, Val Loss: 0.1770, Val Accuracy: 94.74%, F1 Score: 0.9282, AUC Score: 0.9605\n",
            "Runing training output distribution in this epoch:  [0.453 0.25  0.297]\n",
            "Runing training output distribution in this epoch:  [0.335 0.302 0.363]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.304 0.354]\n",
            "Runing training output distribution in this epoch:  [0.343 0.301 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.422 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.4   0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [71/100], Train Loss: 0.2315, Train Accuracy: 91.92%, Val Loss: 0.1772, Val Accuracy: 94.75%, F1 Score: 0.9264, AUC Score: 0.9607\n",
            "Runing training output distribution in this epoch:  [0.344 0.281 0.375]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.375 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.522]\n",
            "Epoch [72/100], Train Loss: 0.2311, Train Accuracy: 91.91%, Val Loss: 0.1779, Val Accuracy: 94.77%, F1 Score: 0.9277, AUC Score: 0.9608\n",
            "Runing training output distribution in this epoch:  [0.297 0.383 0.32 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.303 0.355]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.354]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.339 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.109 0.383 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.402 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.522]\n",
            "Epoch [73/100], Train Loss: 0.2299, Train Accuracy: 91.93%, Val Loss: 0.1808, Val Accuracy: 94.74%, F1 Score: 0.9274, AUC Score: 0.9605\n",
            "Runing training output distribution in this epoch:  [0.312 0.328 0.359]\n",
            "Runing training output distribution in this epoch:  [0.337 0.304 0.359]\n",
            "Runing training output distribution in this epoch:  [0.338 0.301 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing testing output distribution in this epoch:  [0.125 0.406 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.393 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.395 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.399 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Epoch [74/100], Train Loss: 0.2302, Train Accuracy: 91.91%, Val Loss: 0.1775, Val Accuracy: 94.81%, F1 Score: 0.9282, AUC Score: 0.9611\n",
            "Runing training output distribution in this epoch:  [0.352 0.273 0.375]\n",
            "Runing training output distribution in this epoch:  [0.335 0.304 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.298 0.361]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.492 0.438]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.4   0.516]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Epoch [75/100], Train Loss: 0.2312, Train Accuracy: 91.97%, Val Loss: 0.1801, Val Accuracy: 94.75%, F1 Score: 0.9280, AUC Score: 0.9606\n",
            "Runing training output distribution in this epoch:  [0.297 0.305 0.398]\n",
            "Runing training output distribution in this epoch:  [0.343 0.296 0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.359 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.393 0.529]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Epoch [76/100], Train Loss: 0.2313, Train Accuracy: 91.93%, Val Loss: 0.1798, Val Accuracy: 94.74%, F1 Score: 0.9256, AUC Score: 0.9605\n",
            "Runing training output distribution in this epoch:  [0.398 0.281 0.32 ]\n",
            "Runing training output distribution in this epoch:  [0.345 0.299 0.356]\n",
            "Runing training output distribution in this epoch:  [0.345 0.298 0.358]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.343 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.375 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.406 0.515]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.4   0.518]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.401 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Epoch [77/100], Train Loss: 0.2299, Train Accuracy: 91.96%, Val Loss: 0.1790, Val Accuracy: 94.78%, F1 Score: 0.9272, AUC Score: 0.9608\n",
            "Runing training output distribution in this epoch:  [0.344 0.289 0.367]\n",
            "Runing training output distribution in this epoch:  [0.336 0.306 0.358]\n",
            "Runing training output distribution in this epoch:  [0.338 0.307 0.355]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.339 0.305 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.398 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.398 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.523]\n",
            "Epoch [78/100], Train Loss: 0.2305, Train Accuracy: 91.89%, Val Loss: 0.1801, Val Accuracy: 94.74%, F1 Score: 0.9270, AUC Score: 0.9606\n",
            "Runing training output distribution in this epoch:  [0.281 0.25  0.469]\n",
            "Runing training output distribution in this epoch:  [0.341 0.295 0.364]\n",
            "Runing training output distribution in this epoch:  [0.341 0.297 0.362]\n",
            "Runing training output distribution in this epoch:  [0.343 0.299 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.398 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.392 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.393 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Epoch [79/100], Train Loss: 0.2281, Train Accuracy: 92.01%, Val Loss: 0.1767, Val Accuracy: 94.76%, F1 Score: 0.9261, AUC Score: 0.9608\n",
            "Runing training output distribution in this epoch:  [0.359 0.281 0.359]\n",
            "Runing training output distribution in this epoch:  [0.343 0.298 0.359]\n",
            "Runing training output distribution in this epoch:  [0.343 0.302 0.355]\n",
            "Runing training output distribution in this epoch:  [0.344 0.302 0.354]\n",
            "Runing training output distribution in this epoch:  [0.343 0.302 0.356]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.398 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.396 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [80/100], Train Loss: 0.2296, Train Accuracy: 92.04%, Val Loss: 0.1791, Val Accuracy: 94.79%, F1 Score: 0.9265, AUC Score: 0.9609\n",
            "Runing training output distribution in this epoch:  [0.398 0.227 0.375]\n",
            "Runing training output distribution in this epoch:  [0.339 0.297 0.365]\n",
            "Runing training output distribution in this epoch:  [0.343 0.296 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.356]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.398 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.076 0.406 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.399 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.4   0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.399 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Epoch [81/100], Train Loss: 0.2298, Train Accuracy: 91.98%, Val Loss: 0.1758, Val Accuracy: 94.82%, F1 Score: 0.9290, AUC Score: 0.9612\n",
            "Runing training output distribution in this epoch:  [0.312 0.328 0.359]\n",
            "Runing training output distribution in this epoch:  [0.348 0.3   0.351]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.356]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.297 0.633]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.401 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.4   0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.4   0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Epoch [82/100], Train Loss: 0.2305, Train Accuracy: 91.95%, Val Loss: 0.1762, Val Accuracy: 94.83%, F1 Score: 0.9290, AUC Score: 0.9613\n",
            "Runing training output distribution in this epoch:  [0.375 0.25  0.375]\n",
            "Runing training output distribution in this epoch:  [0.328 0.308 0.365]\n",
            "Runing training output distribution in this epoch:  [0.336 0.304 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.356]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.055 0.406 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.389 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.392 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [83/100], Train Loss: 0.2289, Train Accuracy: 91.95%, Val Loss: 0.1775, Val Accuracy: 94.78%, F1 Score: 0.9279, AUC Score: 0.9608\n",
            "Runing training output distribution in this epoch:  [0.352 0.297 0.352]\n",
            "Runing training output distribution in this epoch:  [0.338 0.306 0.356]\n",
            "Runing training output distribution in this epoch:  [0.344 0.3   0.355]\n",
            "Runing training output distribution in this epoch:  [0.345 0.299 0.356]\n",
            "Runing training output distribution in this epoch:  [0.343 0.3   0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.414 0.492]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.394 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.523]\n",
            "Epoch [84/100], Train Loss: 0.2287, Train Accuracy: 92.13%, Val Loss: 0.1750, Val Accuracy: 94.82%, F1 Score: 0.9284, AUC Score: 0.9612\n",
            "Runing training output distribution in this epoch:  [0.297 0.336 0.367]\n",
            "Runing training output distribution in this epoch:  [0.337 0.302 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.337 0.303 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.34  0.301 0.359]\n",
            "Runing training output distribution in this epoch:  [0.339 0.303 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.414 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08 0.4  0.52]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.395 0.525]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.399 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.523]\n",
            "Epoch [85/100], Train Loss: 0.2289, Train Accuracy: 92.08%, Val Loss: 0.1756, Val Accuracy: 94.87%, F1 Score: 0.9298, AUC Score: 0.9616\n",
            "Runing training output distribution in this epoch:  [0.406 0.312 0.281]\n",
            "Runing training output distribution in this epoch:  [0.34  0.292 0.369]\n",
            "Runing training output distribution in this epoch:  [0.34  0.297 0.363]\n",
            "Runing training output distribution in this epoch:  [0.34 0.3  0.36]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.094 0.438 0.469]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.398 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.397 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.4   0.519]\n",
            "Epoch [86/100], Train Loss: 0.2286, Train Accuracy: 91.99%, Val Loss: 0.1800, Val Accuracy: 94.85%, F1 Score: 0.9290, AUC Score: 0.9613\n",
            "Runing training output distribution in this epoch:  [0.242 0.359 0.398]\n",
            "Runing training output distribution in this epoch:  [0.339 0.301 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.343 0.297 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.342 0.299 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.3   0.359]\n",
            "Runing training output distribution in this epoch:  [0.342 0.3   0.358]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.391 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.393 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.394 0.526]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.395 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.396 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Epoch [87/100], Train Loss: 0.2276, Train Accuracy: 92.07%, Val Loss: 0.1775, Val Accuracy: 94.82%, F1 Score: 0.9280, AUC Score: 0.9610\n",
            "Runing training output distribution in this epoch:  [0.234 0.352 0.414]\n",
            "Runing training output distribution in this epoch:  [0.334 0.305 0.361]\n",
            "Runing training output distribution in this epoch:  [0.338 0.308 0.354]\n",
            "Runing training output distribution in this epoch:  [0.339 0.305 0.356]\n",
            "Runing training output distribution in this epoch:  [0.339 0.304 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.109 0.391 0.5  ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.405 0.514]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.403 0.515]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.403 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.401 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.519]\n",
            "Epoch [88/100], Train Loss: 0.2289, Train Accuracy: 92.10%, Val Loss: 0.1748, Val Accuracy: 94.89%, F1 Score: 0.9300, AUC Score: 0.9618\n",
            "Runing training output distribution in this epoch:  [0.398 0.227 0.375]\n",
            "Runing training output distribution in this epoch:  [0.338 0.302 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.43  0.492]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.404 0.514]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.394 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.395 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.394 0.524]\n",
            "Epoch [89/100], Train Loss: 0.2277, Train Accuracy: 92.03%, Val Loss: 0.1755, Val Accuracy: 94.82%, F1 Score: 0.9281, AUC Score: 0.9612\n",
            "Runing training output distribution in this epoch:  [0.352 0.25  0.398]\n",
            "Runing training output distribution in this epoch:  [0.335 0.305 0.36 ]\n",
            "Runing training output distribution in this epoch:  [0.337 0.305 0.359]\n",
            "Runing training output distribution in this epoch:  [0.338 0.304 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.367 0.555]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.401 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.522]\n",
            "Epoch [90/100], Train Loss: 0.2273, Train Accuracy: 92.05%, Val Loss: 0.1728, Val Accuracy: 94.88%, F1 Score: 0.9307, AUC Score: 0.9616\n",
            "Runing training output distribution in this epoch:  [0.328 0.312 0.359]\n",
            "Runing training output distribution in this epoch:  [0.34  0.306 0.353]\n",
            "Runing training output distribution in this epoch:  [0.338 0.308 0.354]\n",
            "Runing training output distribution in this epoch:  [0.339 0.304 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.406 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.404 0.513]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.4   0.517]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Epoch [91/100], Train Loss: 0.2281, Train Accuracy: 92.03%, Val Loss: 0.1759, Val Accuracy: 94.84%, F1 Score: 0.9287, AUC Score: 0.9613\n",
            "Runing training output distribution in this epoch:  [0.375 0.336 0.289]\n",
            "Runing training output distribution in this epoch:  [0.337 0.303 0.361]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.356]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.358]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.375 0.508]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.405 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.402 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.4   0.518]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.398 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Epoch [92/100], Train Loss: 0.2264, Train Accuracy: 92.02%, Val Loss: 0.1763, Val Accuracy: 94.82%, F1 Score: 0.9272, AUC Score: 0.9611\n",
            "Runing training output distribution in this epoch:  [0.305 0.312 0.383]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.357]\n",
            "Runing training output distribution in this epoch:  [0.338 0.306 0.356]\n",
            "Runing training output distribution in this epoch:  [0.339 0.304 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.047 0.477 0.477]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.401 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.401 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.4   0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.4   0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Epoch [93/100], Train Loss: 0.2270, Train Accuracy: 92.08%, Val Loss: 0.1762, Val Accuracy: 94.87%, F1 Score: 0.9299, AUC Score: 0.9616\n",
            "Runing training output distribution in this epoch:  [0.273 0.352 0.375]\n",
            "Runing training output distribution in this epoch:  [0.343 0.299 0.359]\n",
            "Runing training output distribution in this epoch:  [0.341 0.304 0.355]\n",
            "Runing training output distribution in this epoch:  [0.342 0.303 0.355]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.355]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.062 0.344 0.594]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.392 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.401 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.401 0.517]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.4   0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.52 ]\n",
            "Epoch [94/100], Train Loss: 0.2265, Train Accuracy: 92.04%, Val Loss: 0.1751, Val Accuracy: 94.90%, F1 Score: 0.9298, AUC Score: 0.9618\n",
            "Runing training output distribution in this epoch:  [0.281 0.344 0.375]\n",
            "Runing training output distribution in this epoch:  [0.337 0.298 0.365]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.302 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.301 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.102 0.359 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.087 0.391 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.395 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.394 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.397 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Epoch [95/100], Train Loss: 0.2264, Train Accuracy: 92.16%, Val Loss: 0.1771, Val Accuracy: 94.82%, F1 Score: 0.9281, AUC Score: 0.9612\n",
            "Runing training output distribution in this epoch:  [0.344 0.352 0.305]\n",
            "Runing training output distribution in this epoch:  [0.339 0.304 0.357]\n",
            "Runing training output distribution in this epoch:  [0.344 0.298 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.07  0.398 0.531]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.402 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.401 0.518]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.399 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.52 ]\n",
            "Epoch [96/100], Train Loss: 0.2268, Train Accuracy: 92.08%, Val Loss: 0.1761, Val Accuracy: 94.84%, F1 Score: 0.9289, AUC Score: 0.9614\n",
            "Runing training output distribution in this epoch:  [0.391 0.305 0.305]\n",
            "Runing training output distribution in this epoch:  [0.335 0.309 0.356]\n",
            "Runing training output distribution in this epoch:  [0.343 0.303 0.354]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.302 0.358]\n",
            "Runing training output distribution in this epoch:  [0.34  0.303 0.357]\n",
            "Runing testing output distribution in this epoch:  [0.117 0.398 0.484]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.4   0.516]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.401 0.516]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.402 0.514]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.4   0.518]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.399 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.4   0.518]\n",
            "Epoch [97/100], Train Loss: 0.2253, Train Accuracy: 92.18%, Val Loss: 0.1761, Val Accuracy: 94.93%, F1 Score: 0.9284, AUC Score: 0.9618\n",
            "Runing training output distribution in this epoch:  [0.242 0.328 0.43 ]\n",
            "Runing training output distribution in this epoch:  [0.336 0.302 0.362]\n",
            "Runing training output distribution in this epoch:  [0.343 0.301 0.355]\n",
            "Runing training output distribution in this epoch:  [0.342 0.303 0.356]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.356]\n",
            "Runing training output distribution in this epoch:  [0.342 0.301 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.375 0.539]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.395 0.528]\n",
            "Runing testing output distribution in this epoch:  [0.079 0.4   0.521]\n",
            "Runing testing output distribution in this epoch:  [0.078 0.4   0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.398 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.08  0.397 0.524]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.397 0.523]\n",
            "Epoch [98/100], Train Loss: 0.2261, Train Accuracy: 92.09%, Val Loss: 0.1735, Val Accuracy: 94.91%, F1 Score: 0.9291, AUC Score: 0.9618\n",
            "Runing training output distribution in this epoch:  [0.312 0.328 0.359]\n",
            "Runing training output distribution in this epoch:  [0.343 0.306 0.351]\n",
            "Runing training output distribution in this epoch:  [0.347 0.3   0.353]\n",
            "Runing training output distribution in this epoch:  [0.347 0.299 0.354]\n",
            "Runing training output distribution in this epoch:  [0.345 0.301 0.354]\n",
            "Runing training output distribution in this epoch:  [0.342 0.302 0.355]\n",
            "Runing testing output distribution in this epoch:  [0.086 0.367 0.547]\n",
            "Runing testing output distribution in this epoch:  [0.088 0.393 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.084 0.393 0.523]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.397 0.522]\n",
            "Runing testing output distribution in this epoch:  [0.082 0.396 0.522]\n",
            "Epoch [99/100], Train Loss: 0.2259, Train Accuracy: 92.12%, Val Loss: 0.1769, Val Accuracy: 94.85%, F1 Score: 0.9285, AUC Score: 0.9613\n",
            "Runing training output distribution in this epoch:  [0.391 0.258 0.352]\n",
            "Runing training output distribution in this epoch:  [0.343 0.3   0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.356]\n",
            "Runing training output distribution in this epoch:  [0.34  0.304 0.357]\n",
            "Runing training output distribution in this epoch:  [0.341 0.304 0.356]\n",
            "Runing training output distribution in this epoch:  [0.341 0.303 0.356]\n",
            "Runing testing output distribution in this epoch:  [0.125 0.383 0.492]\n",
            "Runing testing output distribution in this epoch:  [0.085 0.395 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.398 0.519]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.397 0.52 ]\n",
            "Runing testing output distribution in this epoch:  [0.083 0.396 0.521]\n",
            "Runing testing output distribution in this epoch:  [0.081 0.398 0.521]\n",
            "Epoch [100/100], Train Loss: 0.2260, Train Accuracy: 92.08%, Val Loss: 0.1768, Val Accuracy: 94.88%, F1 Score: 0.9273, AUC Score: 0.9616\n",
            "Duration: 0:04:17.173166\n"
          ]
        }
      ],
      "source": [
        "## Train the Stage 2 model\n",
        "\n",
        "start_time = datetime.now()\n",
        "\n",
        "num_epochs = 100\n",
        "learning_rate = 1e-5\n",
        "\n",
        "fc_model = FCNet(dropout=0.2).to(device).double()\n",
        "\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(fc_model.parameters(), lr=learning_rate, weight_decay=1e-2)\n",
        "\n",
        "\n",
        "fc_loss_LIST = []\n",
        "fc_acc_LIST = []\n",
        "\n",
        "fc_val_loss_LIST = []\n",
        "fc_val_acc_LIST = []\n",
        "\n",
        "fc_predict = []\n",
        "fc_real = []\n",
        "\n",
        "predict_len = 3\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "\n",
        "    f1_scores = []\n",
        "    auc_scores = []\n",
        "\n",
        "    train_cat = np.array([0,0,0])\n",
        "    test_cat = np.array([0,0,0])\n",
        "\n",
        "    ### Training Model\n",
        "    fc_model.train()\n",
        "    for iter, (input, target) in enumerate(train_loader):\n",
        "      if input.shape[0] > 1:\n",
        "        input = input.to(device).double()\n",
        "        target = target.to(device).double()\n",
        "\n",
        "        output = fc_model(input)\n",
        "        loss = loss_criterion(output, target)\n",
        "\n",
        "        optimizer.zero_grad() # Reset the optimizer tensor gradient every mini-batch\n",
        "        loss.backward() # Do back propagation\n",
        "        optimizer.step() # Update the weight using the gradients from back propagation by learning step\n",
        "\n",
        "        train_loss += loss.item() # Get loss and add to accumulated loss for each epoch\n",
        "        train_total += target.size(0)\n",
        "        output = F.one_hot(torch.max(output, dim=1, keepdim=True)[1], num_classes = 3).squeeze()\n",
        "        train_correct += (torch.argmax(output, dim=1) == torch.argmax(target, dim=1)).sum().item()\n",
        "\n",
        "        train_cat += output.cpu().numpy().sum(axis=0)\n",
        "        if iter%50 == 0:\n",
        "          print('Runing training output distribution in this epoch: ', np.round(train_cat/train_cat.sum(), 3))\n",
        "\n",
        "\n",
        "\n",
        "    ### Evaluating Model\n",
        "    fc_model.eval()\n",
        "    with torch.no_grad():\n",
        "        for iter, (input, target) in enumerate(test_loader):\n",
        "            input = input.to(device).double()\n",
        "            target = target.to(device).double()\n",
        "\n",
        "            val_output = fc_model(input)\n",
        "\n",
        "            val_loss += loss_criterion(val_output, target).item()\n",
        "            val_total += target.size(0)\n",
        "            val_output = F.one_hot(torch.max(val_output, dim=1, keepdim=True)[1], num_classes = 3).squeeze()\n",
        "            val_correct += (torch.argmax(val_output, dim=1) == torch.argmax(target, dim=1)).sum().item()\n",
        "\n",
        "            test_cat += val_output.cpu().numpy().sum(axis=0)\n",
        "            if iter%50 == 0:\n",
        "              print('Runing testing output distribution in this epoch: ', np.round(test_cat/test_cat.sum(), 3))\n",
        "\n",
        "            # Calculate the F1 and AUC scores\n",
        "            f1 = f1_score(target.cpu(), val_output.cpu(), average='macro', zero_division=0)\n",
        "            f1_scores.append(f1)\n",
        "\n",
        "            auc = roc_auc_score(target.cpu().flatten(), val_output.cpu().flatten(), multi_class='ovr', average='weighted')\n",
        "            auc_scores.append(auc)\n",
        "\n",
        "            if epoch + 1 == num_epochs:\n",
        "              val_output_classes = torch.argmax(val_output, dim=1) + 1\n",
        "              fc_predict.extend(val_output_classes.tolist())\n",
        "              target_classes = torch.argmax(target, dim=1) + 1\n",
        "              fc_real.extend(target_classes.tolist())\n",
        "\n",
        "    train_loss = train_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / train_total\n",
        "\n",
        "    val_loss = val_loss / len(test_loader)\n",
        "    val_accuracy = 100 * val_correct / val_total\n",
        "\n",
        "    avg_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "    avg_auc_score = sum(auc_scores) / len(auc_scores)\n",
        "\n",
        "    fc_loss_LIST.append(train_loss)\n",
        "    fc_acc_LIST.append(train_accuracy)\n",
        "\n",
        "    fc_val_loss_LIST.append(val_loss)\n",
        "    fc_val_acc_LIST.append(val_accuracy)\n",
        "\n",
        "    print(\"Epoch [{}/{}], Train Loss: {:.4f}, Train Accuracy: {:.2f}%, Val Loss: {:.4f}, Val Accuracy: {:.2f}%, F1 Score: {:.4f}, AUC Score: {:.4f}\"\n",
        "          .format(epoch+1, num_epochs, train_loss, train_accuracy, val_loss, val_accuracy, avg_f1_score, avg_auc_score))\n",
        "\n",
        "end_time = datetime.now()\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDWmek2bfn6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cc9225-7a29-4523-af76-5fd1b46f2800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "\n",
        "## Save classification model as a pickle file\n",
        "# import gc\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "#2Ov2 -- Custom Dataset 7 with both stages 1 and 2 normalized individually\n",
        "\n",
        "# pick_insert = open('drive/My Drive/MultiVanillaModelPart2Ov2.pkl','wb')\n",
        "# pickle.dump(fc_model, pick_insert)\n",
        "# pick_insert.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(fc_val_acc_LIST)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFO8H610A2vn",
        "outputId": "870ce272-4ae9-464f-fd51-d881d4b0c1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([91.11315147, 91.71478967, 91.92983304, 92.07963853, 92.28501703,\n",
              "       92.39857926, 92.48073066, 92.56288206, 92.65953077, 92.66677942,\n",
              "       92.91564984, 92.98813637, 93.08961751, 93.09203373, 93.20317974,\n",
              "       93.30224467, 93.32640684, 93.43513664, 93.54145021, 93.55836374,\n",
              "       93.67917462, 93.80965037, 93.87247203, 93.87488825, 93.96912074,\n",
              "       94.01261266, 94.06818566, 94.17208302, 94.17449924, 94.25665064,\n",
              "       94.25423442, 94.33638582, 94.36538043, 94.31705608, 94.3750453 ,\n",
              "       94.40887235, 94.43786696, 94.38471017, 94.48860753, 94.5248508 ,\n",
              "       94.52726702, 94.5248508 , 94.52243458, 94.46686157, 94.54659676,\n",
              "       94.58525624, 94.55384541, 94.63358059, 94.55142919, 94.64324546,\n",
              "       94.64324546, 94.66982386, 94.64082925, 94.63841303, 94.68673738,\n",
              "       94.71814821, 94.69398603, 94.69156982, 94.6625752 , 94.75197526,\n",
              "       94.75922391, 94.76647256, 94.7447266 , 94.80271583, 94.75680769,\n",
              "       94.80996448, 94.73989417, 94.79305096, 94.74714282, 94.79788339,\n",
              "       94.80513205, 94.86795371, 94.91869428, 94.74714282, 94.78096987,\n",
              "       94.85587262, 94.78338609, 94.82929422, 94.81962935, 94.77613743,\n",
              "       94.86070505, 94.90661319, 94.86795371, 94.84620775, 94.8945321 ,\n",
              "       94.82929422, 94.81962935, 94.83895909, 94.86070505, 94.87520236,\n",
              "       94.90419697, 94.86312127, 94.88969966, 94.89936453, 94.92352671,\n",
              "       94.84137531, 94.92111049, 94.87036992, 94.88728345, 94.85104018])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "u2c39Xiql5k1",
        "outputId": "3b7b6b01-fa6e-4039-b408-47a1e05c2008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e7476a03150>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig4, ax4 = plt.subplots()\n",
        "ax4.plot(fc_loss_LIST, label = 'Train')\n",
        "ax4.plot(fc_val_loss_LIST, label = 'Validation')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "JELDNX8WqMC1",
        "outputId": "1f74cf5c-ad71-4217-c3a7-096aa100badb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7e74614e3150>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fig5, ax5 = plt.subplots()\n",
        "ax5.plot(fc_acc_LIST, label = 'Train')\n",
        "ax5.plot(fc_val_acc_LIST, label = 'Validation')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDn2_5M1UunY"
      },
      "outputs": [],
      "source": [
        "## Obtain the confusion matrix\n",
        "\n",
        "from sklearn import metrics\n",
        "y_true = fc_real\n",
        "y_pred = fc_predict\n",
        "fc_cf_matrix = metrics.confusion_matrix(y_true, y_pred, labels=[1, 2, 3])\n",
        "\n",
        "xticks = ['REM', 'Wake', 'NREM']\n",
        "yticks = ['REM', 'Wake', 'NREM']\n",
        "\n",
        "fig6, ax6 = plt.subplots(figsize=(5, 5))\n",
        "fig = sns.heatmap(fc_cf_matrix/np.sum(fc_cf_matrix), annot=True,\n",
        "            fmt='.2%', cmap='Blues', cbar=False, xticklabels=xticks, yticklabels=yticks)\n",
        "\n",
        "fig6.suptitle('Confusion Matrix', fontsize=22)\n",
        "ax6.set_xlabel('Predicted', fontsize=18)\n",
        "ax6.set_ylabel('Actual', fontsize=18)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}